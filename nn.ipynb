{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "dependencies:\n",
    "  - python=3.8.17\n",
    "  - numpy=1.24.0\n",
    "  - matplotlib=3.7.1\n",
    "  - pandas=2.0.2 \n",
    "\"\"\"\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "from itertools import product \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# import random\n",
    "# random.seed(42)\n",
    "# np.random.seed(42)\n",
    "# np.random.RandomState(42)\n",
    "# os.environ['TF_DETERMINISTIC_OPS'] = '1' \n",
    "\n",
    "finish_sound = \"afplay /Users/mehmet/Documents/vs-code/winsquare.mp3\"\n",
    "# play sound when finished\n",
    "# os.system(finish_sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5120, 10859) (5120, 4) \n",
      " (640, 10859) (640, 4) \n",
      " (640, 10859) (640, 4)\n"
     ]
    }
   ],
   "source": [
    "# Read data from npy file ( already preprocessed )\n",
    "filename = 'original-numpy'\n",
    "X_train = np.load(f'dataset/{filename}/X_train.npy') # Original\n",
    "#X_train = np.load(f'dataset/{filename}/X_train_pca_2.npy') # PCA\n",
    "X_val = np.load(f'dataset/{filename}/X_val.npy')\n",
    "X_test = np.load(f'dataset/{filename}/X_test.npy')\n",
    "y_train = np.load(f'dataset/{filename}/y_train.npy')\n",
    "y_val = np.load(f'dataset/{filename}/y_val.npy')\n",
    "y_test = np.load(f'dataset/{filename}/y_test.npy')\n",
    "\n",
    "# # Push all X to positive side\n",
    "# X_train = X_train + np.abs(np.min(X_train))\n",
    "# X_val = X_val + np.abs(np.min(X_val))\n",
    "# X_test = X_test + np.abs(np.min(X_test))\n",
    "\n",
    "# # Remove one hot encoding from y\n",
    "# y_train = np.argmax(y_train, axis=1)\n",
    "# y_val = np.argmax(y_val, axis=1)\n",
    "# y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "# X_train = X_train - np.min(X_train, axis=0) + 1e-3\n",
    "# #X_train = X_train / np.max(X_train, axis=0)\n",
    "# X_val = X_val - np.min(X_val, axis=0) + 1e-3\n",
    "# #X_val = X_val / np.max(X_val, axis=0)\n",
    "# X_test = X_test - np.min(X_test, axis=0) + 1e-3\n",
    "# #X_test = X_test / np.max(X_test, axis=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape,'\\n', X_val.shape, y_val.shape,'\\n', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, seed=42):\n",
    "        np.random.seed(seed)\n",
    "        self.n_features = None\n",
    "        self.n_classes = None\n",
    "        \n",
    "        self.input_layer = None\n",
    "        self.layers = []\n",
    "        self.output_layer = None\n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        \n",
    "        self.now = None\n",
    "        self.print_result = True\n",
    "        self.history_steps1 = None\n",
    "        self.history = None\n",
    "        self.validation_accuracy = None\n",
    "        \n",
    "    def validation_accuracy(self):\n",
    "        return self.validation_accuracy\n",
    "    \n",
    "    def history(self):\n",
    "        return self.history\n",
    "    \n",
    "    def load_history(self):\n",
    "        pd_hist = pd.read_csv(f'model-comparison/{self.now}/history.csv')\n",
    "        self.history = np.array(pd_hist.iloc[:,1:])\n",
    "        \n",
    "    def loss(self, X, y):\n",
    "        # Cross Entropy Loss\n",
    "        pred = self.Forward(X)[-1]\n",
    "        return -np.mean(np.sum(y * np.log(pred), axis=1))\n",
    "    \n",
    "    def plot(self, save = True):\n",
    "        # Save history as csv file\n",
    "        history_local = self.history\n",
    "        if type(history_local) is not pd.DataFrame:\n",
    "            history_df = pd.DataFrame(history_local)\n",
    "        if save == True:\n",
    "            hist_csv_file = f'model-comparison/{self.now}/history.csv'\n",
    "            with open(hist_csv_file, mode='w') as f:\n",
    "                history_df.to_csv(f) \n",
    "        # Plot Loss and Accuracy History as Subplots\n",
    "        fig, ax = plt.subplots(1, 2)\n",
    "        fig.set_size_inches(10, 2)\n",
    "        index = np.arange(1,self.history.shape[1]+1)*self.history_steps1\n",
    "        ax[0].plot(index, self.history[0], label='Training Loss')\n",
    "        ax[0].plot(index, self.history[2], label='Validation Loss')\n",
    "        ax[0].set_title('Loss History')\n",
    "        ax[0].set_xlabel('Epoch')\n",
    "        ax[0].set_ylabel('Loss')\n",
    "        ax[0].legend()\n",
    "        # find best validation accuracy and its epoch\n",
    "        best_val_acc = np.max(self.history[3])  \n",
    "        best_val_acc_epoch = (np.argmax(self.history[3]) + 1)*self.history_steps1\n",
    "        label='Best Epoch = '+str(best_val_acc_epoch)+'\\nVal. Acc. = '+str((best_val_acc*100).round(2))+ '%'\n",
    "        ax[1].plot(index, self.history[1], label='Training Accuracy')\n",
    "        ax[1].plot(index, self.history[3], label='Validation Accuracy')\n",
    "        ax[1].plot(best_val_acc_epoch, best_val_acc, 'ro', label=label)\n",
    "        ax[1].set_title('Accuracy History')\n",
    "        ax[1].set_xlabel('Epoch')\n",
    "        ax[1].set_ylabel('Accuracy')\n",
    "        ax[1].legend()\n",
    "        if save is True and self.now is not None:\n",
    "            plt.savefig(f'model-comparison/{self.now}/plot.png')\n",
    "        if self.print_result == True:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close(fig)\n",
    "        \n",
    "    def add_input_layer(self):\n",
    "        self.input_layer = True\n",
    "    \n",
    "    def add_hidden_layer(self, n_neurons, activation=None):\n",
    "        self.layers.append((n_neurons, activation))\n",
    "        \n",
    "    def add_output_layer(self, activation='softmax'):\n",
    "        self.layers.append((activation))\n",
    "\n",
    "    def Initialize_weights(self, weight_init='zero'):\n",
    "        for i in range(len(self.layers)):\n",
    "            \n",
    "            # All middle hidden layers\n",
    "            if i != 0 and i != len(self.layers)-1:\n",
    "                prev_n_neurons = self.layers[i-1][0]\n",
    "                n_neurons = self.layers[i][0]\n",
    "            # First Hidden layer\n",
    "            elif i == 0:\n",
    "                prev_n_neurons = self.n_features\n",
    "                n_neurons = self.layers[i][0]\n",
    "            # Output layer\n",
    "            elif i == len(self.layers)-1:\n",
    "                prev_n_neurons = self.layers[i-1][0]\n",
    "                n_neurons = self.n_classes\n",
    "\n",
    "            # Initialize weights and biases for each layer\n",
    "            if weight_init == 'random':\n",
    "                self.Weights.append(np.random.randn(prev_n_neurons, n_neurons)*0.01)\n",
    "                self.Biases.append(np.random.randn(n_neurons)*0.01)\n",
    "            elif weight_init == 'zero':\n",
    "                self.Weights.append(np.zeros((prev_n_neurons, n_neurons)))\n",
    "                self.Biases.append(np.zeros(n_neurons))\n",
    "            elif weight_init == 'he-normal':\n",
    "                # He Normal Initialization\n",
    "                self.Weights.append(np.random.randn(prev_n_neurons, n_neurons)*np.sqrt(2/prev_n_neurons))\n",
    "                self.Biases.append(np.random.randn(n_neurons)*np.sqrt(2/prev_n_neurons))\n",
    "            elif weight_init == 'xavier-normal':\n",
    "                # Xavier Normal Initialization\n",
    "                self.Weights.append(np.random.randn(prev_n_neurons, n_neurons)*np.sqrt(1/prev_n_neurons))\n",
    "                self.Biases.append(np.random.randn(n_neurons)*np.sqrt(1/prev_n_neurons))\n",
    "            #print(\"Weights shape:\", self.Weights[i].shape)\n",
    "            #print (\"Biases shape:\", self.Biases[i].shape)\n",
    "\n",
    "    def Activation(self, output, activation=None, derivative=False):\n",
    "        if activation == 'relu':\n",
    "            if derivative:\n",
    "                return np.where(output > 0, 1, 0)\n",
    "            else:\n",
    "                return np.maximum(0, output)\n",
    "        elif activation == 'leaky-relu':\n",
    "            if derivative:\n",
    "                return np.where(output > 0, 1, 0.01)\n",
    "            else:\n",
    "                return np.where(output > 0, output, 0.01 * output)\n",
    "            \n",
    "        elif activation == 'sigmoid':\n",
    "            if derivative:\n",
    "                sigmoid_output = self.Activation(output, activation='sigmoid')\n",
    "                return sigmoid_output * (1 - sigmoid_output)\n",
    "            else:\n",
    "                return 1 / (1 + np.exp(-output))\n",
    "        elif activation == 'softmax':\n",
    "            if derivative:\n",
    "                # The derivative of softmax is a bit involved and requires the Jacobian matrix\n",
    "                # For simplicity, we can assume softmax is only used in the output layer\n",
    "                # and compute its derivative accordingly\n",
    "                softmax_output = self.Activation(output, activation='softmax')\n",
    "                return softmax_output * (1 - softmax_output)\n",
    "            else:\n",
    "                exp_output = np.exp(output)\n",
    "                return exp_output / np.sum(exp_output, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "        \n",
    "    def Forward(self, X):\n",
    "        # Forward pass for each layer\n",
    "        input = X\n",
    "        outputs = []\n",
    "        for layer_num in range(len(self.layers)):\n",
    "                layer = self.layers[layer_num]\n",
    "                if layer_num == len(self.layers) - 1:\n",
    "                    activation = layer\n",
    "                else:\n",
    "                    activation = layer[1]\n",
    "                W = self.Weights[layer_num]\n",
    "                b = self.Biases[layer_num]\n",
    "                output = self.Activation(np.dot(input, W) + b, activation)\n",
    "                outputs.append(output)\n",
    "                # Next layer's input is this layer's output\n",
    "                input = output\n",
    "        return outputs\n",
    "\n",
    "    def Backward(self, X, y, outputs):\n",
    "        m = X.shape[0]  # Number of training examples\n",
    "        # Initialize gradients\n",
    "        dW = [0] * len(self.Weights)\n",
    "        db = [0] * len(self.Biases)\n",
    "        \n",
    "        # Backward pass for all layers\n",
    "        for layer_num in reversed(range(len(self.layers))):\n",
    "            if layer_num == 0:\n",
    "                # First hidden layer\n",
    "                input_layer_backward = X\n",
    "            else:\n",
    "                input_layer_backward = outputs[layer_num-1]\n",
    "            output_layer_backward = outputs[layer_num]\n",
    "            layer = self.layers[layer_num]\n",
    "            if layer_num == len(self.layers) - 1:\n",
    "                activation = layer[0]\n",
    "                # Last layer Compute gradients\n",
    "                dZ = output_layer_backward - y\n",
    "                dW[layer_num] = np.dot(input_layer_backward.T, dZ) / m\n",
    "                db[layer_num] = np.sum(dZ, axis=0) / m\n",
    "            else:\n",
    "                activation = layer[1]      \n",
    "                # Hidden layers Compute gradients\n",
    "                dZ = np.dot(dZ, self.Weights[layer_num+1].T) * self.Activation(output_layer_backward, activation, derivative=True)\n",
    "                dW[layer_num] = np.dot(input_layer_backward.T, dZ) / m\n",
    "                db[layer_num] = np.sum(dZ, axis=0) / m\n",
    "            #print(f'Layer {layer_num} dW shape: {dW[layer_num].shape} db shape: {db[layer_num].shape}')\n",
    "                \n",
    "        return dW, db\n",
    "\n",
    "\n",
    "    def fit(self, X, y, X_val, y_val, now=None, max_epoch = 100, print_result=True, save=False,\n",
    "            batch_size=5120, weight_init='zero', lr=0.01, lr_type = 'static', regularization='l2: 0.01',\n",
    "            history_steps = 10, print_step = 50):\n",
    "        \n",
    "        start_time = datetime.datetime.now()\n",
    "        # if there isn't model-comparison folder, create it\n",
    "        if not os.path.exists('model-comparison'):\n",
    "            os.mkdir('model-comparison')\n",
    "        self.print_result = print_result\n",
    "        if now is not None:\n",
    "            self.now = now\n",
    "        # Create folder for current model\n",
    "            if not os.path.exists('model-comparison/'+now):\n",
    "                os.mkdir('model-comparison/'+now)\n",
    "\n",
    "        self.history_steps1 = history_steps\n",
    "        self.history = np.zeros((4,max_epoch//history_steps))\n",
    "        \n",
    "        if regularization[0:2] == 'l2':\n",
    "            # L2 regularization\n",
    "            lmbda = float(regularization[4:])\n",
    "        else:\n",
    "            lmbda = 0\n",
    "            \n",
    "        lr_print = str(lr) + ' ' + lr_type\n",
    "        model_specs = 'NN | Hidden Layers: {} |Batch Size: {} | Weight Init. {} | lr: {} | Lambda: {} | Max Epoch: {} |'.format(str(self.layers), batch_size, weight_init, lr_print, lmbda, max_epoch)\n",
    "        \n",
    "        self.n_features = X.shape[1]\n",
    "        # y is one hot encoded\n",
    "        self.n_classes = y.shape[1]\n",
    "        \n",
    "        self.Initialize_weights(weight_init=weight_init)\n",
    "        \n",
    "        old_val_acc = 0\n",
    "        for epoch in range(1,max_epoch+1):\n",
    "            \n",
    "            # Shuffle all data X and y in the same order every epoch\n",
    "            shuffle_index = np.arange(X.shape[0])\n",
    "            np.random.shuffle(shuffle_index)\n",
    "            X = X[shuffle_index]\n",
    "            y = y[shuffle_index]\n",
    "            \n",
    "            for iteration in range(X.shape[0]//batch_size):          \n",
    "                                              \n",
    "                X_batch = X[batch_size*iteration:batch_size*(iteration+1)]\n",
    "                y_batch = y[batch_size*iteration:batch_size*(iteration+1)]\n",
    "            \n",
    "                # For all layers, Forward pass one time\n",
    "                outputs = self.Forward(X_batch)\n",
    "                # For all layers, Backward pass one time\n",
    "                dW, db = self.Backward(X_batch, y_batch, outputs)\n",
    "            \n",
    "                # Update weights and biases\n",
    "                for layer_num in range(len(self.layers)):\n",
    "                    self.Weights[layer_num] -= lr * dW[layer_num] + 2 * lmbda * self.Weights[layer_num]\n",
    "                    self.Biases[layer_num] -= lr * db[layer_num]\n",
    "\n",
    "            \n",
    "            if epoch % history_steps == 0:\n",
    "                # how to calculate accuracy\n",
    "                t_loss = self.loss(X, y)\n",
    "                val_loss = self.loss(X_val, y_val)\n",
    "                # Compute accuracy\n",
    "                pred = self.Forward(X)[-1]\n",
    "                accuracy = np.mean(np.argmax(pred, axis=1) == np.argmax(y, axis=1))\n",
    "                # Validation accuracy\n",
    "                pred_val = self.predict(X_val)\n",
    "                val_acc = np.mean(pred_val == np.argmax(y_val, axis=1))\n",
    "                self.validation_accuracy = val_acc\n",
    "                self.history[:,(epoch//history_steps)-1] = np.array([t_loss, accuracy, val_loss, val_acc])\n",
    "            \n",
    "                if epoch % print_step == 0:\n",
    "                    line1 = 'Epoch: ' + str(epoch)\n",
    "                    line2 = ' | Loss: ' + str(t_loss)[:5] + ' | Accuracy: ' + str(accuracy)[0:5]\n",
    "                    line3 = ' | Val. Loss: ' + str(val_loss)[:5] + ' | Val. Acc: ' + str(val_acc)[0:5]\n",
    "                    #line2 = ' | Accuracy: ' + str(accuracy)[0:5]\n",
    "                    #line3 = ' | Val. Acc: ' + str(val_acc)[0:5]\n",
    "                    if print_result == True:\n",
    "                        print(line1 + line2 + line3)\n",
    "                    if now is not None:\n",
    "                        with open('model-comparison/{}/log.txt'.format(now), 'a') as f:\n",
    "                            f.write(line1 + line2 + line3 + '\\n')\n",
    "                    \n",
    "                    if abs(old_val_acc-val_acc) < 0.005:\n",
    "                        #lr = lr * 0.9\n",
    "                        #print(f'Learning rate is updated to {lr}')\n",
    "                        pass\n",
    "                    \n",
    "                    old_val_acc = val_acc\n",
    "                    \n",
    "            if epoch == max_epoch:\n",
    "                end_time = datetime.datetime.now()\n",
    "                if print_result == True:\n",
    "                    print('Training finished. Time elapsed:', end_time - start_time, '\\n')\n",
    "                    print('Accuracy: ', str(accuracy)[0:5], 'Val. Accuracy: ', str(val_acc)[0:5])\n",
    "                val_acc_print = str(val_acc*100)+ '00'\n",
    "                if now is not None:\n",
    "                    with open('model-comparison/{}/log.txt'.format(now), 'a') as f:\n",
    "                        write_line = 'Training finished. Time elapsed: ' + str(end_time - start_time) + '\\n'\n",
    "                        f.write(write_line)\n",
    "                    with open('model-comparison/{}/{}-val-acc.txt'.format(now,val_acc_print[0:5]), 'w') as f:\n",
    "                        f.write(model_specs)\n",
    "                    with open('model-comparison/last.txt', 'w') as f:\n",
    "                        f.write(str(now))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pred_l = self.Forward(X)\n",
    "        pred = pred_l[-1]\n",
    "        return np.argmax(pred, axis=1)\n",
    "\n",
    "    def save_weights(self):\n",
    "        # if there isn't model folder, create it\n",
    "        if not os.path.exists('model-comparison/{}/model'.format(self.now)):\n",
    "            os.mkdir('model-comparison/{}/model'.format(self.now))\n",
    "        # save history steps\n",
    "        with open('model-comparison/{}/model/history_steps.txt'.format(self.now), 'w') as f:\n",
    "            f.write(str(self.history_steps1))\n",
    "        # save layers first to txt file\n",
    "        with open('model-comparison/{}/model/layers.txt'.format(self.now), 'w') as f:\n",
    "            f.write(str(self.layers))       \n",
    "        # save weights and biases \n",
    "        for i in range(len(self.layers)):\n",
    "            filename = 'model-comparison/{}/model/weights{}.npy'.format(self.now, i+1)\n",
    "            np.save(filename, self.Weights[i])\n",
    "            filename2 = 'model-comparison/{}/model/biases{}.npy'.format(self.now, i+1)\n",
    "            np.save(filename2, self.Biases[i])\n",
    "            \n",
    "    def load_weights(self, now):\n",
    "        # load history steps\n",
    "        with open('model-comparison/{}/model/history_steps.txt'.format(now), 'r') as f:\n",
    "            self.history_steps1 = int(f.read())\n",
    "        # load layers from txt file\n",
    "        with open('model-comparison/{}/model/layers.txt'.format(now), 'r') as f:\n",
    "            self.layers = list(eval(f.read()))\n",
    "        # load weights and biases\n",
    "        for i in range(len(self.layers)):\n",
    "            filename = 'model-comparison/{}/model/weights{}.npy'.format(now, i+1)\n",
    "            self.Weights.append(np.load(filename))\n",
    "            filename2 = 'model-comparison/{}/model/biases{}.npy'.format(now, i+1)\n",
    "            self.Biases.append(np.load(filename2))\n",
    "        self.now = now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateModel():\n",
    "    # Class to evaluate model performance, similar to sklearn.metrics ClassificationReport and ConfusionMatrix\n",
    "    def __init__(self, y_true, y_pred, str1, now, save=True, print_result=True):\n",
    "        self.y_true = np.argmax(y_true, axis=1)\n",
    "        self.y_pred = y_pred\n",
    "        if save == True:\n",
    "            os.mkdir('model-comparison/'+now+'/'+str1)\n",
    "            np.savetxt('model-comparison/{}/{}/pred.csv'.format(now,str1), y_pred, delimiter=',', fmt='%d')\n",
    "        \n",
    "        result = self.classification_report()\n",
    "        fpr0 = 100 - float(result['precision'][0][0:4])\n",
    "        line1 = 'Accuracy is: ' + str(result['f1-score']['accuracy'])\n",
    "        line2 = 'F1 Score is: ' + str(result['f1-score']['weighted avg'])\n",
    "        line3 = 'Precision of Class 0 is: ' + '{0:.2f}'.format(100-fpr0)+ ' %'\n",
    "        line4 = '\\nClassification Report:'\n",
    "        line5 = '\\nConfusion Matrix:'\n",
    "        cm = self.confusion_matrix()\n",
    "        line6 = '\\n'\n",
    "        res_total = line1 + '\\n' + line2 + '\\n' + line3 + '\\n' + line4 + '\\n' + str(result) + '\\n' + line5 + '\\n' + str(cm) + '\\n' + line6\n",
    "        # write to file\n",
    "        if save == True:\n",
    "            with open('model-comparison/{}/{}/report.txt'.format(now,str1), 'w') as f:\n",
    "                f.write(res_total)\n",
    "        if print_result == True:\n",
    "            print(res_total)\n",
    "\n",
    "    def accuracy_score(self, y_t, y_p):\n",
    "        correct = sum(y_t == y_p)\n",
    "        return correct / len(y_t)\n",
    "\n",
    "    def scores(self, y_t, y_p, class_label= 1):\n",
    "        true = y_t == class_label\n",
    "        pred = y_p == class_label\n",
    "        tp = sum(true & pred)\n",
    "        fp = sum(~true & pred) \n",
    "        fn = sum(true & ~pred)\n",
    "        tn = sum(~true & ~pred) \n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        return precision, recall, f1\n",
    "    \n",
    "    def confusion_matrix(self,labels=None):\n",
    "        labels = labels if labels else sorted(set(self.y_true) | set(self.y_pred))        \n",
    "        indexes = {v:i for i, v in enumerate(labels)}\n",
    "        matrix = np.zeros((len(indexes),len(indexes))).astype(int)\n",
    "        for t, p in zip(self.y_true, self.y_pred):\n",
    "            matrix[indexes[t], indexes[p]] += 1\n",
    "        # print('Confusion Matrix: ')\n",
    "        # print(pd.DataFrame(matrix, index=labels, columns=labels))\n",
    "        return pd.DataFrame(matrix, index=labels, columns=labels)\n",
    "\n",
    "    def classification_report(self):\n",
    "        output_dict = {}\n",
    "        support_list = []\n",
    "        precision_list = []\n",
    "        recall_list = []\n",
    "        f1_list = []\n",
    "        for i in np.unique(self.y_true):\n",
    "            support = sum(self.y_true == i)\n",
    "            precision, recall, f1 = self.scores(self.y_true, self.y_pred, class_label=i)\n",
    "            output_dict[i] = {'precision':precision, 'recall':recall, 'f1-score':f1, 'support':support}\n",
    "            precision_list.append(precision)\n",
    "            recall_list.append(recall)\n",
    "            f1_list.append(f1)\n",
    "            support_list.append(support)\n",
    "        support = np.sum(support_list)\n",
    "        output_dict['accuracy'] = {'precision':0, 'recall':0, 'f1-score':self.accuracy_score(self.y_true, self.y_pred), 'support':support}\n",
    "        # macro avg\n",
    "        macro_precision = np.mean(precision_list)\n",
    "        macro_recall = np.mean(recall_list)\n",
    "        macro_f1 = np.mean(f1_list)\n",
    "        output_dict['macro avg'] = {'precision':macro_precision, 'recall':macro_recall, 'f1-score':macro_f1, 'support':support}\n",
    "        # weighted avg\n",
    "        weighted_precision = np.average(precision_list, weights=support_list)\n",
    "        weighted_recall = np.average(recall_list, weights=support_list)\n",
    "        weighted_f1 = np.average(f1_list, weights=support_list)\n",
    "        output_dict['weighted avg'] = {'precision':weighted_precision, 'recall':weighted_recall, 'f1-score':weighted_f1, 'support':support}\n",
    "        # convert to dataframe and format\n",
    "        report_d = pd.DataFrame(output_dict).T\n",
    "        annot = report_d.copy()\n",
    "        annot.iloc[:, 0:3] = (annot.iloc[:, 0:3]*100).applymap('{:.2f}'.format) + ' %'\n",
    "        annot['support'] = annot['support'].astype(int)\n",
    "        annot.loc['accuracy','precision'] = ''\n",
    "        annot.loc['accuracy','recall'] = ''\n",
    "        return annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearch(model_options, X_train, y_train, X_val, y_val, X_test, y_test, print_result=False, seed=42, history_steps=10):\n",
    "    # Grid Search Function\n",
    "    best_metric = 0\n",
    "    for i in range(len(model_options)):\n",
    "        models = model_options[i]\n",
    "        model_number = i + 1\n",
    "        now = datetime.datetime.now().strftime(\"%d-%m-%H-%M\")\n",
    "        # Create folder for current model\n",
    "        if not os.path.exists('model-comparison/'+now):\n",
    "            os.mkdir('model-comparison/'+now)\n",
    "        else:\n",
    "            now = now + str('--1')\n",
    "            os.mkdir('model-comparison/'+now)\n",
    "        model = NN(seed=seed)\n",
    "        start_time = datetime.datetime.now()\n",
    "        model.add_input_layer() # 10859\n",
    "        hidden_layers = len(models[-1])\n",
    "        for i in range(hidden_layers):\n",
    "            model.add_hidden_layer(models[-1][i][0], activation=models[-1][i][1])\n",
    "        model.add_output_layer()\n",
    "        model.fit(X_train, y_train, X_val, y_val, now, print_result=print_result, max_epoch=models[0], save=True, history_steps=history_steps,\n",
    "                  weight_init= models[1], batch_size=models[2], lr=models[3], lr_type=models[4], regularization=models[5])\n",
    "        end_time = datetime.datetime.now()\n",
    "        time_elapsed = str(end_time - start_time)[2:7]\n",
    "        metric = model.validation_accuracy\n",
    "        model.save_weights()\n",
    "        model.plot()\n",
    "        y_pred = model.predict(X_val)\n",
    "        results = EvaluateModel(y_val, y_pred, 'val', now, print_result=print_result)\n",
    "        y_pred = model.predict(X_test)\n",
    "        results = EvaluateModel(y_test, y_pred, 'test', now, print_result=print_result)\n",
    "        if metric > best_metric:\n",
    "            best_metric = metric\n",
    "            best_model = now\n",
    "        print('Model ', str(model_number), ' saved with name: ', now)\n",
    "        print(models, 'Val-Accuracy:', metric)\n",
    "\n",
    "        # append to txt file\n",
    "        lr_print = str(models[3]) + ' ' + models[4]\n",
    "        model_specs = 'NN | Batch Size: {} | Weight Init: {} | Lr: {} | Reg: {} | Max Epoch: {}'.format(models[2], models[1], lr_print, models[5], models[0])\n",
    "        with open('model-comparison/best-models.txt', 'a') as f:\n",
    "            f.write(now + ' | ' + model_specs + ' | ' + str(metric) + ' | Time Elapsed: '+ time_elapsed + ' | Hidden Layers: '+ str(models[-1]) +'\\n')\n",
    "        print(len(model_options)-model_number, 'models left to train.')\n",
    "    best_metric = str(best_metric*100)[:5]\n",
    "    print('Best Model is:', best_model, 'with validation accuracy:', best_metric, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(hidden_layers, max_epoch, batch_size, weight_init, lr, lr_type, regularization):\n",
    "    model_options = [[max_epoch, weight_init, batch_size, lr, lr_type, regularization, hidden_layers]]\n",
    "    return model_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train New Model\n",
    "hidden_layers = [(64, 'leaky-relu'),\n",
    "                 (32, 'leaky-relu')]\n",
    "\n",
    "model_parameters = TrainModel(hidden_layers,\n",
    "    max_epoch=1000, batch_size=1, weight_init='he-normal', \n",
    "    lr=0.01, lr_type='static', regularization='l2: 0.0001')\n",
    "\n",
    "GridSearch(model_parameters, X_train, y_train, X_val, y_val, X_test, y_test, print_result=True, seed=42, history_steps=1)\n",
    "\n",
    "os.system(finish_sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations: 6\n",
      "Combination 1: (1000, 'he-normal', 512, 0.01, 'static', 'l2: 0.001', [(64, 'leaky-relu'), (32, 'leaky-relu')])\n"
     ]
    }
   ],
   "source": [
    "# Grid Search Combinations\n",
    "hidden_layers = [[(64, 'leaky-relu'),\n",
    "                 (32, 'leaky-relu')]]\n",
    "max_epoch = [1000]\n",
    "weight_init = ['he-normal']\n",
    "batch_size = [512, 5120] # [1, 512, 5120]\n",
    "lr = [0.01] # [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "lr_type = ['static']\n",
    "regularization = ['l2: 0.001', 'l2: 0.0001','l2: 0.0001']\n",
    "params = [max_epoch, weight_init, batch_size, lr, lr_type, regularization, hidden_layers]\n",
    "model_options = list(product(*params))\n",
    "print('Number of combinations:', len(model_options))\n",
    "print('Combination 1:', model_options[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train All Combinations\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m GridSearch(model_options[\u001b[39m0\u001b[39;49m:\u001b[39m1\u001b[39;49m], X_train, y_train, X_val, y_val, X_test, y_test, seed\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m, history_steps\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m os\u001b[39m.\u001b[39msystem(finish_sound)\n",
      "\u001b[1;32m/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     model\u001b[39m.\u001b[39madd_hidden_layer(models[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][i][\u001b[39m0\u001b[39m], activation\u001b[39m=\u001b[39mmodels[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][i][\u001b[39m1\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb#X24sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39madd_output_layer()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, X_val, y_val, now, print_result\u001b[39m=\u001b[39;49mprint_result, max_epoch\u001b[39m=\u001b[39;49mmodels[\u001b[39m0\u001b[39;49m], save\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, history_steps\u001b[39m=\u001b[39;49mhistory_steps,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb#X24sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m           weight_init\u001b[39m=\u001b[39;49m models[\u001b[39m1\u001b[39;49m], batch_size\u001b[39m=\u001b[39;49mmodels[\u001b[39m2\u001b[39;49m], lr\u001b[39m=\u001b[39;49mmodels[\u001b[39m3\u001b[39;49m], lr_type\u001b[39m=\u001b[39;49mmodels[\u001b[39m4\u001b[39;49m], regularization\u001b[39m=\u001b[39;49mmodels[\u001b[39m5\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb#X24sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m end_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb#X24sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m time_elapsed \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(end_time \u001b[39m-\u001b[39m start_time)[\u001b[39m2\u001b[39m:\u001b[39m7\u001b[39m]\n",
      "\u001b[1;32m/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb#X24sZmlsZQ%3D%3D?line=239'>240</a>\u001b[0m y_batch \u001b[39m=\u001b[39m y[batch_size\u001b[39m*\u001b[39miteration:batch_size\u001b[39m*\u001b[39m(iteration\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb#X24sZmlsZQ%3D%3D?line=241'>242</a>\u001b[0m \u001b[39m# For all layers, Forward pass one time\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb#X24sZmlsZQ%3D%3D?line=242'>243</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mForward(X_batch)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb#X24sZmlsZQ%3D%3D?line=243'>244</a>\u001b[0m \u001b[39m# For all layers, Backward pass one time\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb#X24sZmlsZQ%3D%3D?line=244'>245</a>\u001b[0m dW, db \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mBackward(X_batch, y_batch, outputs)\n",
      "\u001b[1;32m/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb#X24sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m W \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mWeights[layer_num]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb#X24sZmlsZQ%3D%3D?line=155'>156</a>\u001b[0m b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mBiases[layer_num]\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb#X24sZmlsZQ%3D%3D?line=156'>157</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mActivation(np\u001b[39m.\u001b[39;49mdot(\u001b[39minput\u001b[39;49m, W) \u001b[39m+\u001b[39m b, activation)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb#X24sZmlsZQ%3D%3D?line=157'>158</a>\u001b[0m outputs\u001b[39m.\u001b[39mappend(output)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/nn.ipynb#X24sZmlsZQ%3D%3D?line=158'>159</a>\u001b[0m \u001b[39m# Next layer's input is this layer's output\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train All Combinations\n",
    "GridSearch(model_options[0:1], X_train, y_train, X_val, y_val, X_test, y_test, seed=42, history_steps=10)\n",
    "os.system(finish_sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "# Train Model\n",
    "now = datetime.datetime.now().strftime(\"%d-%m-%H-%M\")\n",
    "model = NN()\n",
    "model.add_input_layer() # 10859\n",
    "model.add_hidden_layer(64, activation='leaky-relu')\n",
    "model.add_hidden_layer(32, activation='leaky-relu')\n",
    "model.add_output_layer()\n",
    "model.fit(X_train, y_train, X_val, y_val, max_epoch=1000, now=now, print_result=True, save=True,\n",
    "          batch_size=5120, weight_init='he-normal', lr=0.01, lr_type='static', regularization='l2: 0',\n",
    "          history_steps=10, print_step=50)\n",
    "\n",
    "model.save_weights()\n",
    "model.plot()\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "results = EvaluateModel(y_val, y_pred, 'val', now=now, save=True, print_result=True)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "results = EvaluateModel(y_test, y_pred, 'test', now=now, save=True, print_result=True) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "# Load Model\n",
    "now = '20-12-05-29'\n",
    "\n",
    "model = NN()\n",
    "model.load_weights(now)\n",
    "model.load_history()\n",
    "model.plot(save=False)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "results = EvaluateModel(y_val, y_pred, 'val', now=now, save=False, print_result=True)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "results = EvaluateModel(y_test, y_pred, 'test', now=now, save=False, print_result=True)\n",
    "\"\"\" "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs464",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
