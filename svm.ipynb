{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "dependencies:\n",
    "  - python=3.8.17\n",
    "  - numpy=1.24.0\n",
    "  - matplotlib=3.7.1\n",
    "  - pandas=2.0.2 \n",
    "\"\"\"\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "from itertools import product \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# import random\n",
    "# random.seed(42)\n",
    "# np.random.seed(42)\n",
    "# np.random.RandomState(42)\n",
    "# os.environ['TF_DETERMINISTIC_OPS'] = '1' \n",
    "\n",
    "finish_sound = \"afplay /Users/mehmet/Documents/vs-code/winsquare.mp3\"\n",
    "# play sound when finished\n",
    "# os.system(finish_sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5120, 10859) (5120, 4) \n",
      " (640, 10859) (640, 4) \n",
      " (640, 10859) (640, 4)\n"
     ]
    }
   ],
   "source": [
    "# Read data from npy file ( already preprocessed )\n",
    "filename = 'original-numpy'\n",
    "# filename = 'pca-numpy'\n",
    "X_train = np.load(f'dataset/{filename}/X_train.npy')\n",
    "X_val = np.load(f'dataset/{filename}/X_val.npy')\n",
    "X_test = np.load(f'dataset/{filename}/X_test.npy')\n",
    "y_train = np.load(f'dataset/{filename}/y_train.npy')\n",
    "y_val = np.load(f'dataset/{filename}/y_val.npy')\n",
    "y_test = np.load(f'dataset/{filename}/y_test.npy')\n",
    "\n",
    "print(X_train.shape, y_train.shape,'\\n', X_val.shape, y_val.shape,'\\n', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, seed=42):\n",
    "        np.random.seed(seed)\n",
    "        self.W = None\n",
    "        self.now = None\n",
    "        self.print_result = True\n",
    "        self.history_steps1 = None\n",
    "        self.history = None\n",
    "        self.validation_accuracy = None\n",
    "        self.degree = None\n",
    "        self.alpha = None\n",
    "        self.constant = None\n",
    "        \n",
    "    def validation_accuracy(self):\n",
    "        return self.validation_accuracy\n",
    "    \n",
    "    def history(self):\n",
    "        return self.history\n",
    "    \n",
    "    def load_history(self):\n",
    "        pd_hist = pd.read_csv(f'model-comparison/{self.now}/history.csv')\n",
    "        self.history = np.array(pd_hist.iloc[:,1:])\n",
    "        \n",
    "    def plot(self, save = True):\n",
    "        # Save history as csv file\n",
    "        history_local = self.history\n",
    "        if type(history_local) is not pd.DataFrame:\n",
    "            history_df = pd.DataFrame(history_local)\n",
    "        if save == True:\n",
    "            hist_csv_file = f'model-comparison/{self.now}/history.csv'\n",
    "            with open(hist_csv_file, mode='w') as f:\n",
    "                history_df.to_csv(f) \n",
    "        # Plot Loss and Accuracy History as Subplots\n",
    "        fig, ax = plt.subplots(1, 2)\n",
    "        fig.set_size_inches(10, 2)\n",
    "        index = np.arange(1,self.history.shape[1]+1)*self.history_steps1\n",
    "\n",
    "        ax[0].plot(index, self.history[0], label='Training Loss')\n",
    "        ax[0].plot(index, self.history[2], label='Validation Loss')\n",
    "        ax[0].set_title('Loss History')\n",
    "        ax[0].set_xlabel('Epoch')\n",
    "        ax[0].set_ylabel('Loss')\n",
    "        ax[0].legend()\n",
    "        # find best validation accuracy and its epoch\n",
    "        best_val_acc = np.max(self.history[3])  \n",
    "        best_val_acc_epoch = (np.argmax(self.history[3]) + 1)*self.history_steps1\n",
    "        label='Best Epoch = '+str(best_val_acc_epoch)+'\\nVal. Acc. = '+str((best_val_acc*100).round(2))+ '%'\n",
    "        ax[1].plot(index, self.history[1], label='Training Accuracy')\n",
    "        ax[1].plot(index, self.history[3], label='Validation Accuracy')\n",
    "        ax[1].plot(best_val_acc_epoch, best_val_acc, 'ro', label=label)\n",
    "        ax[1].set_title('Accuracy History')\n",
    "        ax[1].set_xlabel('Epoch')\n",
    "        ax[1].set_ylabel('Accuracy')\n",
    "        ax[1].legend()\n",
    "        if save is True and self.now is not None:\n",
    "            plt.savefig(f'model-comparison/{self.now}/plot.png')\n",
    "        if self.print_result == True:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close(fig)\n",
    "        \n",
    "\n",
    "    def loss(self, X_nonbiased, y, W):\n",
    "        # Hinge loss\n",
    "        if X_nonbiased.shape[1] != W.shape[0]:\n",
    "            ones=np.ones(X_nonbiased.shape[0])\n",
    "            X=np.c_[ones,X_nonbiased]\n",
    "        else:\n",
    "            X = X_nonbiased\n",
    "        scores = X.dot(W)\n",
    "        num_samples = X.shape[0]\n",
    "        correct_class_mask = (np.arange(num_samples), y)\n",
    "        margins = np.maximum(0, scores - scores[correct_class_mask][:, np.newaxis] + 1)\n",
    "        margins[correct_class_mask] = 0\n",
    "        loss = np.sum(margins)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def gradient(self, X, y, W):\n",
    "        \n",
    "        # Linear kernel\n",
    "        scores = X.dot(W)\n",
    "        num_samples = X.shape[0]\n",
    "        correct_class_mask = (np.arange(num_samples), y)\n",
    "        margins = np.maximum(0, scores - scores[correct_class_mask][:, np.newaxis] + 1)\n",
    "        margins[correct_class_mask] = 0\n",
    "        grad_mask = (margins > 0).astype(float)\n",
    "        grad_mask[correct_class_mask] = -np.sum(grad_mask, axis=1)\n",
    "    \n",
    "        # # Polynomial kernel\n",
    "        # scores = np.power((self.alpha * X.dot(X.T) + self.constant), self.degree)\n",
    "        # num_samples = X.shape[0]\n",
    "        # correct_class_mask = (np.arange(num_samples), y)\n",
    "        # margins = np.maximum(0, scores - scores[correct_class_mask][:, np.newaxis] + 1)\n",
    "        # margins[correct_class_mask] = 0\n",
    "        # grad_mask = (margins > 0).astype(float)\n",
    "        # grad_mask[correct_class_mask] = -np.sum(grad_mask, axis=1)\n",
    "        \n",
    "        return X.T.dot(grad_mask)\n",
    "        \n",
    "    def fit(self, X_nonbiased, y, X_val, y_val, now=None, print_result = True,\n",
    "            batch_size=5120, weight_init='zero', lr=0.01, lr_type = 'static', lmbda=0.01, max_epoch=1000,\n",
    "            degree = 3, alpha = 1, constant = 1,\n",
    "            history_steps = 1, print_step = 100):\n",
    "        self.degree = degree\n",
    "        self.alpha = alpha\n",
    "        self.constant = constant\n",
    "        start_time = datetime.datetime.now()\n",
    "        # if there isn't model-comparison folder, create it\n",
    "        if not os.path.exists('model-comparison'):\n",
    "            os.mkdir('model-comparison')\n",
    "        self.print_result = print_result\n",
    "        if now is not None:\n",
    "            self.now = now\n",
    "        # Create folder for current model\n",
    "            if not os.path.exists('model-comparison/'+now):\n",
    "                os.mkdir('model-comparison/'+now)\n",
    "\n",
    "        self.history_steps1 = history_steps\n",
    "        self.history = np.zeros((4,max_epoch//history_steps))\n",
    "        y_onehot = y\n",
    "        lr_print = str(lr) + ' ' + lr_type\n",
    "        model_specs = 'SVM | Batch Size: {} | Weight Init. {} | lr: {} | Lambda: {} | Max Epoch: {} |'.format(batch_size, weight_init, lr_print, lmbda, max_epoch)\n",
    "\n",
    "        # add bias\n",
    "        ones=np.ones(X_nonbiased.shape[0])\n",
    "        X=np.c_[ones,X_nonbiased]\n",
    "        \n",
    "\n",
    "        #self.W = np.random.rand(num_features, num_classes)\n",
    "        \n",
    "        # zero initialization\n",
    "        # bias included in W\n",
    "        \n",
    "        self.W = np.zeros((X.shape[1], y.shape[1]))\n",
    "        # For Poly Kernel\n",
    "        # self.W = np.zeros((num_features, 512))\n",
    "\n",
    "        # One hot encoded to not one hot encoded\n",
    "        y = np.argmax(y, axis=1)\n",
    "        y_val = np.argmax(y_val, axis=1)\n",
    "        \n",
    "        # Print loss and accuracy every 100 iterations or every max_iter//10 iterations if max_iter >= 1000\n",
    "        # if max_epoch >= 1000:\n",
    "        #     print_step = max_epoch // 10\n",
    "\n",
    "        # Gradient Descent\n",
    "        for epoch in range(1,max_epoch+1):\n",
    "            \n",
    "            # Shuffle all data X and y in the same order every epoch\n",
    "            shuffle_index = np.arange(X.shape[0])\n",
    "            np.random.shuffle(shuffle_index)\n",
    "            X = X[shuffle_index]\n",
    "            y = y[shuffle_index]\n",
    "            \n",
    "            for iteration in range(X.shape[0]//batch_size):          \n",
    "                                              \n",
    "                X_batch = X[batch_size*iteration:batch_size*(iteration+1)]\n",
    "                y_batch = y[batch_size*iteration:batch_size*(iteration+1)]\n",
    "            \n",
    "                reg_term = lmbda * self.W\n",
    "                reg_term[0] = 0\n",
    "                \n",
    "                                \n",
    "                dRSS = self.gradient(X_batch, y_batch, self.W)\n",
    "                gradient = (dRSS/batch_size) + reg_term\n",
    "                \n",
    "                if lr_type[0:8] == 'momentum':\n",
    "                    if epoch == 1:\n",
    "                        last_gradient = gradient\n",
    "                    else:\n",
    "                        momentum = float(lr_type[10:])\n",
    "                        gradient = gradient + momentum * last_gradient\n",
    "                        last_gradient = gradient\n",
    "                \n",
    "                \n",
    "                self.W -= lr * gradient\n",
    "                \n",
    "            if lr_type[0:8] == 'adaptive' and epoch % 3000 == 0:\n",
    "                    k = float(lr_type[9:])\n",
    "                    lr *= k\n",
    "                    if print_result == True:\n",
    "                        print('Learning rate changed to: ', lr)\n",
    "\n",
    "            # For each 100 epochs print losses and accuracy\n",
    "            if epoch % history_steps == 0:\n",
    "                # how to calculate accuracy\n",
    "                loss = self.loss(X, y, self.W)\n",
    "                val_loss = self.loss(X_val, y_val, self.W)\n",
    "                accuracy = np.mean(self.predict(X) == y)  \n",
    "                val_acc = np.mean(self.predict(X_val) == y_val)   \n",
    "                self.validation_accuracy = val_acc\n",
    "                self.history[:,(epoch//history_steps)-1] = np.array([loss, accuracy, val_loss, val_acc])\n",
    "                \n",
    "                if epoch % print_step == 0:\n",
    "                    line1 = 'Epoch: ' + str(epoch)\n",
    "                    line2 = ' | Loss: ' + str(loss)[:5] + ' | Accuracy: ' + str(accuracy)[0:5]\n",
    "                    line3 = ' | Val. Loss: ' + str(val_loss)[:5] + ' | Val. Acc: ' + str(val_acc)[0:5]\n",
    "                    # line2 = ' | Loss: ' + str(round(loss)) + ' | Accuracy: ' + str(accuracy)[0:5]\n",
    "                    # line3 = ' | Val. Loss: ' + str(round(val_loss)) + ' | Val. Acc: ' + str(val_acc)[0:5]\n",
    "                    if print_result == True:\n",
    "                        print(line1 + line2 + line3)\n",
    "                    if now is not None:\n",
    "                        with open('model-comparison/{}/log.txt'.format(now), 'a') as f:\n",
    "                            f.write(line1 + line2 + line3 + '\\n')\n",
    "                            \n",
    "            if epoch == max_epoch:\n",
    "                end_time = datetime.datetime.now()\n",
    "                if print_result == True:\n",
    "                    print('Training finished. Time elapsed:', end_time - start_time, '\\n')\n",
    "                    print('Accuracy: ', str(accuracy)[0:5], 'Val. Accuracy: ', str(val_acc)[0:5])\n",
    "                val_acc_print = str(val_acc*100)+ '00'\n",
    "                if now is not None:\n",
    "                    with open('model-comparison/{}/log.txt'.format(now), 'a') as f:\n",
    "                        write_line = 'Training finished. Time elapsed: ' + str(end_time - start_time) + '\\n'\n",
    "                        f.write(write_line)\n",
    "                    with open('model-comparison/{}/{}-val-acc.txt'.format(now,val_acc_print[0:5]), 'w') as f:\n",
    "                        f.write(model_specs)\n",
    "                    with open('model-comparison/last.txt', 'w') as f:\n",
    "                        f.write(str(now))\n",
    "                            \n",
    "    def predict(self, X_nonbiased):\n",
    "        if X_nonbiased.shape[1] != self.W.shape[0]: \n",
    "            # add bias\n",
    "            ones=np.ones(X_nonbiased.shape[0])\n",
    "            X=np.c_[ones,X_nonbiased]\n",
    "        else:\n",
    "            X = X_nonbiased\n",
    "        \n",
    "        scores = X.dot(self.W)\n",
    "        predictions = np.argmax(scores, axis=1)\n",
    "        return predictions\n",
    "    \n",
    "    def save_weights(self):\n",
    "        # save history steps\n",
    "        with open('model-comparison/{}/history_steps.txt'.format(self.now), 'w') as f:\n",
    "            f.write(str(self.history_steps1))\n",
    "        # save weights (bias included in W)\n",
    "        filename = 'model-comparison/{}/weights.npy'.format(self.now)\n",
    "        np.save(filename, self.W)\n",
    "    def load_weights(self, now):\n",
    "        # load history steps\n",
    "        with open('model-comparison/{}/history_steps.txt'.format(now), 'r') as f:\n",
    "            self.history_steps1 = int(f.read())\n",
    "        # load weights (bias included in W)\n",
    "        filename = 'model-comparison/{}/weights.npy'.format(now)\n",
    "        self.W = np.load(filename)\n",
    "        self.now = now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateModel():\n",
    "    # Class to evaluate model performance, similar to sklearn.metrics ClassificationReport and ConfusionMatrix\n",
    "    def __init__(self, y_true, y_pred, str1, now, save=True, print_result=True):\n",
    "        self.y_true = np.argmax(y_true, axis=1)\n",
    "        self.y_pred = y_pred\n",
    "        if save == True:\n",
    "            os.mkdir('model-comparison/'+now+'/'+str1)\n",
    "            np.savetxt('model-comparison/{}/{}/pred.csv'.format(now,str1), y_pred, delimiter=',', fmt='%d')\n",
    "        \n",
    "        result = self.classification_report()\n",
    "        fpr0 = 100 - float(result['precision'][0][0:4])\n",
    "        line1 = 'Accuracy is: ' + str(result['f1-score']['accuracy'])\n",
    "        line2 = 'F1 Score is: ' + str(result['f1-score']['weighted avg'])\n",
    "        line3 = 'Precision of Class 0 is: ' + '{0:.2f}'.format(100-fpr0)+ ' %'\n",
    "        line4 = '\\nClassification Report:'\n",
    "        line5 = '\\nConfusion Matrix:'\n",
    "        cm = self.confusion_matrix()\n",
    "        line6 = '\\n'\n",
    "        res_total = line1 + '\\n' + line2 + '\\n' + line3 + '\\n' + line4 + '\\n' + str(result) + '\\n' + line5 + '\\n' + str(cm) + '\\n' + line6\n",
    "        # write to file\n",
    "        if save == True:\n",
    "            with open('model-comparison/{}/{}/report.txt'.format(now,str1), 'w') as f:\n",
    "                f.write(res_total)\n",
    "        if print_result == True:\n",
    "            print(res_total)\n",
    "\n",
    "    def accuracy_score(self, y_t, y_p):\n",
    "        correct = sum(y_t == y_p)\n",
    "        return correct / len(y_t)\n",
    "\n",
    "    def scores(self, y_t, y_p, class_label= 1):\n",
    "        true = y_t == class_label\n",
    "        pred = y_p == class_label\n",
    "        tp = sum(true & pred)\n",
    "        fp = sum(~true & pred) \n",
    "        fn = sum(true & ~pred)\n",
    "        tn = sum(~true & ~pred) \n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        return precision, recall, f1\n",
    "    \n",
    "    def confusion_matrix(self,labels=None):\n",
    "        labels = labels if labels else sorted(set(self.y_true) | set(self.y_pred))        \n",
    "        indexes = {v:i for i, v in enumerate(labels)}\n",
    "        matrix = np.zeros((len(indexes),len(indexes))).astype(int)\n",
    "        for t, p in zip(self.y_true, self.y_pred):\n",
    "            matrix[indexes[t], indexes[p]] += 1\n",
    "        # print('Confusion Matrix: ')\n",
    "        # print(pd.DataFrame(matrix, index=labels, columns=labels))\n",
    "        return pd.DataFrame(matrix, index=labels, columns=labels)\n",
    "\n",
    "    def classification_report(self):\n",
    "        output_dict = {}\n",
    "        support_list = []\n",
    "        precision_list = []\n",
    "        recall_list = []\n",
    "        f1_list = []\n",
    "        for i in np.unique(self.y_true):\n",
    "            support = sum(self.y_true == i)\n",
    "            precision, recall, f1 = self.scores(self.y_true, self.y_pred, class_label=i)\n",
    "            output_dict[i] = {'precision':precision, 'recall':recall, 'f1-score':f1, 'support':support}\n",
    "            precision_list.append(precision)\n",
    "            recall_list.append(recall)\n",
    "            f1_list.append(f1)\n",
    "            support_list.append(support)\n",
    "        support = np.sum(support_list)\n",
    "        output_dict['accuracy'] = {'precision':0, 'recall':0, 'f1-score':self.accuracy_score(self.y_true, self.y_pred), 'support':support}\n",
    "        # macro avg\n",
    "        macro_precision = np.mean(precision_list)\n",
    "        macro_recall = np.mean(recall_list)\n",
    "        macro_f1 = np.mean(f1_list)\n",
    "        output_dict['macro avg'] = {'precision':macro_precision, 'recall':macro_recall, 'f1-score':macro_f1, 'support':support}\n",
    "        # weighted avg\n",
    "        weighted_precision = np.average(precision_list, weights=support_list)\n",
    "        weighted_recall = np.average(recall_list, weights=support_list)\n",
    "        weighted_f1 = np.average(f1_list, weights=support_list)\n",
    "        output_dict['weighted avg'] = {'precision':weighted_precision, 'recall':weighted_recall, 'f1-score':weighted_f1, 'support':support}\n",
    "        # convert to dataframe and format\n",
    "        report_d = pd.DataFrame(output_dict).T\n",
    "        annot = report_d.copy()\n",
    "        annot.iloc[:, 0:3] = (annot.iloc[:, 0:3]*100).applymap('{:.2f}'.format) + ' %'\n",
    "        annot['support'] = annot['support'].astype(int)\n",
    "        annot.loc['accuracy','precision'] = ''\n",
    "        annot.loc['accuracy','recall'] = ''\n",
    "        return annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearch(model_options, X_train, y_train, X_val, y_val, X_test, y_test, print_result=False, seed=42, history_steps=100):\n",
    "    # Grid Search Function\n",
    "    best_metric = 0\n",
    "    for i in range(len(model_options)):\n",
    "        models = model_options[i]\n",
    "        model_number = i + 1\n",
    "        now = datetime.datetime.now().strftime(\"%d-%m-%H-%M\")\n",
    "        # Create folder for current model\n",
    "        if not os.path.exists('model-comparison/'+now):\n",
    "            os.mkdir('model-comparison/'+now)\n",
    "        else:\n",
    "            now = now + str('--1')\n",
    "            os.mkdir('model-comparison/'+now)\n",
    "        model = SVM(seed=seed)\n",
    "        start_time = datetime.datetime.now()\n",
    "        model.fit(X_train, y_train, X_val, y_val, now, print_result=print_result, max_epoch=models[0], history_steps=history_steps,\n",
    "                  weight_init= models[1], batch_size=models[2], lr=models[3], lr_type=models[4], lmbda=models[5])\n",
    "        end_time = datetime.datetime.now()\n",
    "        time_elapsed = str(end_time - start_time)[2:7]\n",
    "        metric = model.validation_accuracy\n",
    "        model.save_weights()\n",
    "        model.plot()\n",
    "        y_pred = model.predict(X_val)\n",
    "        results = EvaluateModel(y_val, y_pred, 'val', now, print_result=print_result)\n",
    "        y_pred = model.predict(X_test)\n",
    "        results = EvaluateModel(y_test, y_pred, 'test', now, print_result=print_result)\n",
    "        if metric > best_metric:\n",
    "            best_metric = metric\n",
    "            best_model = now\n",
    "        print('Model ', str(model_number), ' saved with name: ', now)\n",
    "        print(models, 'Val-Accuracy:', metric)\n",
    "\n",
    "        # append to txt file\n",
    "        lr_print = str(models[3]) + ' ' + models[4]\n",
    "        model_specs = 'SVM | Batch Size: {} | Weight Init: {} | lr: {} | Lambda: {} | Max Epoch: {}'.format(models[2], models[1], lr_print, models[5], models[0])\n",
    "        with open('model-comparison/best-models.txt', 'a') as f:\n",
    "            f.write(now + ' | ' + model_specs + ' | ' + str(metric) + ' | Time Elapsed: '+ time_elapsed +'\\n')\n",
    "        print(len(model_options)-model_number, 'models left to train.')\n",
    "    best_metric = str(best_metric*100)[:5]\n",
    "    print('Best Model is:', best_model, 'with validation accuracy:', best_metric, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(max_epoch, batch_size, weight_init, lr, lr_type, lmbda):\n",
    "    model_options = [[max_epoch, weight_init, batch_size, lr, lr_type, lmbda]]\n",
    "    return model_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train New Model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model_parameters \u001b[39m=\u001b[39m TrainModel(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     max_epoch\u001b[39m=\u001b[39m\u001b[39m2500\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m, weight_init\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mzero\u001b[39m\u001b[39m'\u001b[39m, lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m, lr_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstatic\u001b[39m\u001b[39m'\u001b[39m, lmbda\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m GridSearch(model_parameters, X_train, y_train, X_val, y_val, X_test, y_test, print_result\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, seed\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m os\u001b[39m.\u001b[39msystem(finish_sound)\n",
      "\u001b[1;32m/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model \u001b[39m=\u001b[39m SVM(seed\u001b[39m=\u001b[39mseed)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m start_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, X_val, y_val, now, print_result\u001b[39m=\u001b[39;49mprint_result, max_epoch\u001b[39m=\u001b[39;49mmodels[\u001b[39m0\u001b[39;49m], \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m           weight_init\u001b[39m=\u001b[39;49m models[\u001b[39m1\u001b[39;49m], batch_size\u001b[39m=\u001b[39;49mmodels[\u001b[39m2\u001b[39;49m], lr\u001b[39m=\u001b[39;49mmodels[\u001b[39m3\u001b[39;49m], lr_type\u001b[39m=\u001b[39;49mmodels[\u001b[39m4\u001b[39;49m], lmbda\u001b[39m=\u001b[39;49mmodels[\u001b[39m5\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m end_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m time_elapsed \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(end_time \u001b[39m-\u001b[39m start_time)[\u001b[39m2\u001b[39m:\u001b[39m7\u001b[39m]\n",
      "\u001b[1;32m/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=187'>188</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(X, y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=188'>189</a>\u001b[0m val_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(X_val, y_val, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=189'>190</a>\u001b[0m accuracy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X) \u001b[39m==\u001b[39m y)  \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=190'>191</a>\u001b[0m val_acc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(X_val) \u001b[39m==\u001b[39m y_val)   \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=191'>192</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_accuracy \u001b[39m=\u001b[39m val_acc\n",
      "\u001b[1;32m/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=226'>227</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=227'>228</a>\u001b[0m     X \u001b[39m=\u001b[39m X_nonbiased\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=229'>230</a>\u001b[0m scores \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mdot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=230'>231</a>\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(scores, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mehmet/Documents/vs-code/EEE485-Statistical-Learning-and-Data-Analytics/svm.ipynb#W6sZmlsZQ%3D%3D?line=231'>232</a>\u001b[0m \u001b[39mreturn\u001b[39;00m predictions\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train New Model\n",
    "model_parameters = TrainModel(\n",
    "    max_epoch=2500, batch_size=512, weight_init='zero', lr=0.001, lr_type='static', lmbda=0.1)\n",
    "\n",
    "GridSearch(model_parameters, X_train, y_train, X_val, y_val, X_test, y_test, print_result=True, seed=42, history_steps=1)\n",
    "\n",
    "os.system(finish_sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations: 84\n",
      "Combination 1: (2500, 'zero', 512, 0.1, 'static', 0.1)\n"
     ]
    }
   ],
   "source": [
    "# Grid Search Combinations\n",
    "\n",
    "max_epoch = [2500]\n",
    "weight_init = ['zero']\n",
    "#batch_size = [1, 512, 5120]\n",
    "batch_size = [512, 5120]\n",
    "lr = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "#lr = [0.01, 0.001, 0.0001]\n",
    "\n",
    "lr_type = ['static']\n",
    "regularization = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0]\n",
    "#regularization = [0.01, 0.005, 0.001, 0.0005, 0.0001]\n",
    "params = [max_epoch, weight_init, batch_size, lr, lr_type, regularization]\n",
    "model_options = list(product(*params))\n",
    "print('Number of combinations:', len(model_options))\n",
    "print('Combination 1:', model_options[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  1  saved with name:  19-12-00-30\n",
      "(2500, 'zero', 512, 0.1, 'static', 0.1) Val-Accuracy: 0.615625\n",
      "83 models left to train.\n",
      "Model  2  saved with name:  19-12-00-35\n",
      "(2500, 'zero', 512, 0.1, 'static', 0.01) Val-Accuracy: 0.8359375\n",
      "82 models left to train.\n",
      "Model  3  saved with name:  19-12-00-39\n",
      "(2500, 'zero', 512, 0.1, 'static', 0.001) Val-Accuracy: 0.85\n",
      "81 models left to train.\n",
      "Model  4  saved with name:  19-12-00-44\n",
      "(2500, 'zero', 512, 0.1, 'static', 0.0001) Val-Accuracy: 0.84375\n",
      "80 models left to train.\n",
      "Model  5  saved with name:  19-12-00-49\n",
      "(2500, 'zero', 512, 0.1, 'static', 1e-05) Val-Accuracy: 0.8359375\n",
      "79 models left to train.\n",
      "Model  6  saved with name:  19-12-00-54\n",
      "(2500, 'zero', 512, 0.1, 'static', 1e-06) Val-Accuracy: 0.8328125\n",
      "78 models left to train.\n",
      "Model  7  saved with name:  19-12-00-58\n",
      "(2500, 'zero', 512, 0.1, 'static', 0) Val-Accuracy: 0.8328125\n",
      "77 models left to train.\n",
      "Model  8  saved with name:  19-12-01-03\n",
      "(2500, 'zero', 512, 0.01, 'static', 0.1) Val-Accuracy: 0.8375\n",
      "76 models left to train.\n",
      "Model  9  saved with name:  19-12-01-08\n",
      "(2500, 'zero', 512, 0.01, 'static', 0.01) Val-Accuracy: 0.8703125\n",
      "75 models left to train.\n",
      "Model  10  saved with name:  19-12-01-13\n",
      "(2500, 'zero', 512, 0.01, 'static', 0.001) Val-Accuracy: 0.865625\n",
      "74 models left to train.\n",
      "Model  11  saved with name:  19-12-01-17\n",
      "(2500, 'zero', 512, 0.01, 'static', 0.0001) Val-Accuracy: 0.8640625\n",
      "73 models left to train.\n",
      "Model  12  saved with name:  19-12-01-22\n",
      "(2500, 'zero', 512, 0.01, 'static', 1e-05) Val-Accuracy: 0.859375\n",
      "72 models left to train.\n",
      "Model  13  saved with name:  19-12-01-27\n",
      "(2500, 'zero', 512, 0.01, 'static', 1e-06) Val-Accuracy: 0.859375\n",
      "71 models left to train.\n",
      "Model  14  saved with name:  19-12-01-32\n",
      "(2500, 'zero', 512, 0.01, 'static', 0) Val-Accuracy: 0.8609375\n",
      "70 models left to train.\n",
      "Model  15  saved with name:  19-12-01-37\n",
      "(2500, 'zero', 512, 0.001, 'static', 0.1) Val-Accuracy: 0.9390625\n",
      "69 models left to train.\n",
      "Model  16  saved with name:  19-12-01-42\n",
      "(2500, 'zero', 512, 0.001, 'static', 0.01) Val-Accuracy: 0.921875\n",
      "68 models left to train.\n",
      "Model  17  saved with name:  19-12-01-47\n",
      "(2500, 'zero', 512, 0.001, 'static', 0.001) Val-Accuracy: 0.90625\n",
      "67 models left to train.\n",
      "Model  18  saved with name:  19-12-01-52\n",
      "(2500, 'zero', 512, 0.001, 'static', 0.0001) Val-Accuracy: 0.903125\n",
      "66 models left to train.\n",
      "Model  19  saved with name:  19-12-01-57\n",
      "(2500, 'zero', 512, 0.001, 'static', 1e-05) Val-Accuracy: 0.903125\n",
      "65 models left to train.\n",
      "Model  20  saved with name:  19-12-02-01\n",
      "(2500, 'zero', 512, 0.001, 'static', 1e-06) Val-Accuracy: 0.9046875\n",
      "64 models left to train.\n",
      "Model  21  saved with name:  19-12-02-06\n",
      "(2500, 'zero', 512, 0.001, 'static', 0) Val-Accuracy: 0.9046875\n",
      "63 models left to train.\n",
      "Model  22  saved with name:  19-12-02-11\n",
      "(2500, 'zero', 512, 0.0001, 'static', 0.1) Val-Accuracy: 0.928125\n",
      "62 models left to train.\n",
      "Model  23  saved with name:  19-12-02-16\n",
      "(2500, 'zero', 512, 0.0001, 'static', 0.01) Val-Accuracy: 0.9125\n",
      "61 models left to train.\n",
      "Model  24  saved with name:  19-12-02-21\n",
      "(2500, 'zero', 512, 0.0001, 'static', 0.001) Val-Accuracy: 0.9125\n",
      "60 models left to train.\n",
      "Model  25  saved with name:  19-12-02-26\n",
      "(2500, 'zero', 512, 0.0001, 'static', 0.0001) Val-Accuracy: 0.9125\n",
      "59 models left to train.\n",
      "Model  26  saved with name:  19-12-02-31\n",
      "(2500, 'zero', 512, 0.0001, 'static', 1e-05) Val-Accuracy: 0.9109375\n",
      "58 models left to train.\n",
      "Model  27  saved with name:  19-12-02-36\n",
      "(2500, 'zero', 512, 0.0001, 'static', 1e-06) Val-Accuracy: 0.9125\n",
      "57 models left to train.\n",
      "Model  28  saved with name:  19-12-02-41\n",
      "(2500, 'zero', 512, 0.0001, 'static', 0) Val-Accuracy: 0.9125\n",
      "56 models left to train.\n",
      "Model  29  saved with name:  19-12-02-46\n",
      "(2500, 'zero', 512, 1e-05, 'static', 0.1) Val-Accuracy: 0.8421875\n",
      "55 models left to train.\n",
      "Model  30  saved with name:  19-12-02-51\n",
      "(2500, 'zero', 512, 1e-05, 'static', 0.01) Val-Accuracy: 0.8453125\n",
      "54 models left to train.\n",
      "Model  31  saved with name:  19-12-02-56\n",
      "(2500, 'zero', 512, 1e-05, 'static', 0.001) Val-Accuracy: 0.8453125\n",
      "53 models left to train.\n",
      "Model  32  saved with name:  19-12-03-01\n",
      "(2500, 'zero', 512, 1e-05, 'static', 0.0001) Val-Accuracy: 0.8453125\n",
      "52 models left to train.\n",
      "Model  33  saved with name:  19-12-03-06\n",
      "(2500, 'zero', 512, 1e-05, 'static', 1e-05) Val-Accuracy: 0.8453125\n",
      "51 models left to train.\n",
      "Model  34  saved with name:  19-12-03-11\n",
      "(2500, 'zero', 512, 1e-05, 'static', 1e-06) Val-Accuracy: 0.8453125\n",
      "50 models left to train.\n",
      "Model  35  saved with name:  19-12-03-16\n",
      "(2500, 'zero', 512, 1e-05, 'static', 0) Val-Accuracy: 0.8453125\n",
      "49 models left to train.\n",
      "Model  36  saved with name:  19-12-03-21\n",
      "(2500, 'zero', 512, 1e-06, 'static', 0.1) Val-Accuracy: 0.659375\n",
      "48 models left to train.\n",
      "Model  37  saved with name:  19-12-03-26\n",
      "(2500, 'zero', 512, 1e-06, 'static', 0.01) Val-Accuracy: 0.659375\n",
      "47 models left to train.\n",
      "Model  38  saved with name:  19-12-03-31\n",
      "(2500, 'zero', 512, 1e-06, 'static', 0.001) Val-Accuracy: 0.659375\n",
      "46 models left to train.\n",
      "Model  39  saved with name:  19-12-03-36\n",
      "(2500, 'zero', 512, 1e-06, 'static', 0.0001) Val-Accuracy: 0.659375\n",
      "45 models left to train.\n",
      "Model  40  saved with name:  19-12-03-41\n",
      "(2500, 'zero', 512, 1e-06, 'static', 1e-05) Val-Accuracy: 0.659375\n",
      "44 models left to train.\n",
      "Model  41  saved with name:  19-12-03-46\n",
      "(2500, 'zero', 512, 1e-06, 'static', 1e-06) Val-Accuracy: 0.659375\n",
      "43 models left to train.\n",
      "Model  42  saved with name:  19-12-03-51\n",
      "(2500, 'zero', 512, 1e-06, 'static', 0) Val-Accuracy: 0.659375\n",
      "42 models left to train.\n",
      "Model  43  saved with name:  19-12-03-56\n",
      "(2500, 'zero', 5120, 0.1, 'static', 0.1) Val-Accuracy: 0.621875\n",
      "41 models left to train.\n",
      "Model  44  saved with name:  19-12-04-01\n",
      "(2500, 'zero', 5120, 0.1, 'static', 0.01) Val-Accuracy: 0.8375\n",
      "40 models left to train.\n",
      "Model  45  saved with name:  19-12-04-06\n",
      "(2500, 'zero', 5120, 0.1, 'static', 0.001) Val-Accuracy: 0.828125\n",
      "39 models left to train.\n",
      "Model  46  saved with name:  19-12-04-11\n",
      "(2500, 'zero', 5120, 0.1, 'static', 0.0001) Val-Accuracy: 0.8296875\n",
      "38 models left to train.\n",
      "Model  47  saved with name:  19-12-04-16\n",
      "(2500, 'zero', 5120, 0.1, 'static', 1e-05) Val-Accuracy: 0.828125\n",
      "37 models left to train.\n",
      "Model  48  saved with name:  19-12-04-21\n",
      "(2500, 'zero', 5120, 0.1, 'static', 1e-06) Val-Accuracy: 0.8265625\n",
      "36 models left to train.\n",
      "Model  49  saved with name:  19-12-04-26\n",
      "(2500, 'zero', 5120, 0.1, 'static', 0) Val-Accuracy: 0.8296875\n",
      "35 models left to train.\n",
      "Model  50  saved with name:  19-12-04-31\n",
      "(2500, 'zero', 5120, 0.01, 'static', 0.1) Val-Accuracy: 0.8578125\n",
      "34 models left to train.\n",
      "Model  51  saved with name:  19-12-04-37\n",
      "(2500, 'zero', 5120, 0.01, 'static', 0.01) Val-Accuracy: 0.8578125\n",
      "33 models left to train.\n",
      "Model  52  saved with name:  19-12-04-42\n",
      "(2500, 'zero', 5120, 0.01, 'static', 0.001) Val-Accuracy: 0.8515625\n",
      "32 models left to train.\n",
      "Model  53  saved with name:  19-12-04-47\n",
      "(2500, 'zero', 5120, 0.01, 'static', 0.0001) Val-Accuracy: 0.8515625\n",
      "31 models left to train.\n",
      "Model  54  saved with name:  19-12-04-52\n",
      "(2500, 'zero', 5120, 0.01, 'static', 1e-05) Val-Accuracy: 0.8484375\n",
      "30 models left to train.\n",
      "Model  55  saved with name:  19-12-04-57\n",
      "(2500, 'zero', 5120, 0.01, 'static', 1e-06) Val-Accuracy: 0.85\n",
      "29 models left to train.\n",
      "Model  56  saved with name:  19-12-05-02\n",
      "(2500, 'zero', 5120, 0.01, 'static', 0) Val-Accuracy: 0.85\n",
      "28 models left to train.\n",
      "Model  57  saved with name:  19-12-05-07\n",
      "(2500, 'zero', 5120, 0.001, 'static', 0.1) Val-Accuracy: 0.91875\n",
      "27 models left to train.\n",
      "Model  58  saved with name:  19-12-05-12\n",
      "(2500, 'zero', 5120, 0.001, 'static', 0.01) Val-Accuracy: 0.9078125\n",
      "26 models left to train.\n",
      "Model  59  saved with name:  19-12-05-17\n",
      "(2500, 'zero', 5120, 0.001, 'static', 0.001) Val-Accuracy: 0.9046875\n",
      "25 models left to train.\n",
      "Model  60  saved with name:  19-12-05-22\n",
      "(2500, 'zero', 5120, 0.001, 'static', 0.0001) Val-Accuracy: 0.90625\n",
      "24 models left to train.\n",
      "Model  61  saved with name:  19-12-05-28\n",
      "(2500, 'zero', 5120, 0.001, 'static', 1e-05) Val-Accuracy: 0.9109375\n",
      "23 models left to train.\n",
      "Model  62  saved with name:  19-12-05-33\n",
      "(2500, 'zero', 5120, 0.001, 'static', 1e-06) Val-Accuracy: 0.90625\n",
      "22 models left to train.\n",
      "Model  63  saved with name:  19-12-05-38\n",
      "(2500, 'zero', 5120, 0.001, 'static', 0) Val-Accuracy: 0.90625\n",
      "21 models left to train.\n",
      "Model  64  saved with name:  19-12-05-43\n",
      "(2500, 'zero', 5120, 0.0001, 'static', 0.1) Val-Accuracy: 0.8421875\n",
      "20 models left to train.\n",
      "Model  65  saved with name:  19-12-05-48\n",
      "(2500, 'zero', 5120, 0.0001, 'static', 0.01) Val-Accuracy: 0.8453125\n",
      "19 models left to train.\n",
      "Model  66  saved with name:  19-12-05-53\n",
      "(2500, 'zero', 5120, 0.0001, 'static', 0.001) Val-Accuracy: 0.84375\n",
      "18 models left to train.\n",
      "Model  67  saved with name:  19-12-05-58\n",
      "(2500, 'zero', 5120, 0.0001, 'static', 0.0001) Val-Accuracy: 0.8453125\n",
      "17 models left to train.\n",
      "Model  68  saved with name:  19-12-06-03\n",
      "(2500, 'zero', 5120, 0.0001, 'static', 1e-05) Val-Accuracy: 0.84375\n",
      "16 models left to train.\n",
      "Model  69  saved with name:  19-12-06-08\n",
      "(2500, 'zero', 5120, 0.0001, 'static', 1e-06) Val-Accuracy: 0.8453125\n",
      "15 models left to train.\n",
      "Model  70  saved with name:  19-12-06-13\n",
      "(2500, 'zero', 5120, 0.0001, 'static', 0) Val-Accuracy: 0.84375\n",
      "14 models left to train.\n",
      "Model  71  saved with name:  19-12-06-18\n",
      "(2500, 'zero', 5120, 1e-05, 'static', 0.1) Val-Accuracy: 0.659375\n",
      "13 models left to train.\n",
      "Model  72  saved with name:  19-12-06-23\n",
      "(2500, 'zero', 5120, 1e-05, 'static', 0.01) Val-Accuracy: 0.659375\n",
      "12 models left to train.\n",
      "Model  73  saved with name:  19-12-06-29\n",
      "(2500, 'zero', 5120, 1e-05, 'static', 0.001) Val-Accuracy: 0.659375\n",
      "11 models left to train.\n",
      "Model  74  saved with name:  19-12-06-34\n",
      "(2500, 'zero', 5120, 1e-05, 'static', 0.0001) Val-Accuracy: 0.659375\n",
      "10 models left to train.\n",
      "Model  75  saved with name:  19-12-06-39\n",
      "(2500, 'zero', 5120, 1e-05, 'static', 1e-05) Val-Accuracy: 0.659375\n",
      "9 models left to train.\n",
      "Model  76  saved with name:  19-12-06-44\n",
      "(2500, 'zero', 5120, 1e-05, 'static', 1e-06) Val-Accuracy: 0.659375\n",
      "8 models left to train.\n",
      "Model  77  saved with name:  19-12-06-49\n",
      "(2500, 'zero', 5120, 1e-05, 'static', 0) Val-Accuracy: 0.659375\n",
      "7 models left to train.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8c/r_rgg7rn3_1753l7y7gh1vqm0000gn/T/ipykernel_71561/3857328777.py:40: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1 = 2 * (precision * recall) / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  78  saved with name:  19-12-06-54\n",
      "(2500, 'zero', 5120, 1e-06, 'static', 0.1) Val-Accuracy: 0.5484375\n",
      "6 models left to train.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8c/r_rgg7rn3_1753l7y7gh1vqm0000gn/T/ipykernel_71561/3857328777.py:40: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1 = 2 * (precision * recall) / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  79  saved with name:  19-12-06-59\n",
      "(2500, 'zero', 5120, 1e-06, 'static', 0.01) Val-Accuracy: 0.5484375\n",
      "5 models left to train.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8c/r_rgg7rn3_1753l7y7gh1vqm0000gn/T/ipykernel_71561/3857328777.py:40: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1 = 2 * (precision * recall) / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  80  saved with name:  19-12-07-04\n",
      "(2500, 'zero', 5120, 1e-06, 'static', 0.001) Val-Accuracy: 0.5484375\n",
      "4 models left to train.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8c/r_rgg7rn3_1753l7y7gh1vqm0000gn/T/ipykernel_71561/3857328777.py:40: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1 = 2 * (precision * recall) / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  81  saved with name:  19-12-07-09\n",
      "(2500, 'zero', 5120, 1e-06, 'static', 0.0001) Val-Accuracy: 0.5484375\n",
      "3 models left to train.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8c/r_rgg7rn3_1753l7y7gh1vqm0000gn/T/ipykernel_71561/3857328777.py:40: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1 = 2 * (precision * recall) / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  82  saved with name:  19-12-07-14\n",
      "(2500, 'zero', 5120, 1e-06, 'static', 1e-05) Val-Accuracy: 0.5484375\n",
      "2 models left to train.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8c/r_rgg7rn3_1753l7y7gh1vqm0000gn/T/ipykernel_71561/3857328777.py:40: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1 = 2 * (precision * recall) / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  83  saved with name:  19-12-07-19\n",
      "(2500, 'zero', 5120, 1e-06, 'static', 1e-06) Val-Accuracy: 0.5484375\n",
      "1 models left to train.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8c/r_rgg7rn3_1753l7y7gh1vqm0000gn/T/ipykernel_71561/3857328777.py:40: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1 = 2 * (precision * recall) / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  84  saved with name:  19-12-07-24\n",
      "(2500, 'zero', 5120, 1e-06, 'static', 0) Val-Accuracy: 0.5484375\n",
      "0 models left to train.\n",
      "Best Model is: 19-12-01-37 with validation accuracy: 93.90 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search All Combinations\n",
    "\n",
    "GridSearch(model_options, X_train, y_train, X_val, y_val, X_test, y_test, seed=42, history_steps=1)\n",
    "os.system(finish_sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "# Train New Model\n",
    "now = datetime.datetime.now().strftime(\"%d-%m-%H-%M\")\n",
    "\n",
    "model = SVM(seed=42)\n",
    "model.fit(X_train, y_train, X_val, y_val, now=now, print_result=True,\n",
    "        lr=0.001, lmbda=0.001, max_epoch=1000)\n",
    "\n",
    "model.save_weights()\n",
    "model.plot()\n",
    "\n",
    "# Validation Set Results\n",
    "y_pred = model.predict(X_val)\n",
    "results = EvaluateModel(y_val, y_pred, 'val', now)\n",
    "\n",
    "# Test Set Results\n",
    "y_pred = model.predict(X_test)\n",
    "results = EvaluateModel(y_test, y_pred, 'test', now)\n",
    "\"\"\" "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs464",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
